# ğŸ¥ RAG-Based YouTube Video Chat AI (Streaming)

A **Retrieval-Augmented Generation (RAG)** based web application that allows users to **ask questions about any YouTube video** and receive **real-time streamed answers** from an LLM using the videoâ€™s transcript as context.

The system extracts the YouTube transcript, chunks it, stores it in a vector database (FAISS), retrieves relevant context, and streams answers token-by-token to the frontend.

---

## ğŸš€ Features

* ğŸ”— YouTube Transcript Extraction
* ğŸ§  RAG Pipeline using LangChain
* ğŸ“¦ FAISS Vector Store
* ğŸ” Semantic Search with HuggingFace Embeddings
* âš¡ Real-time Streaming LLM Output
* ğŸŒ FastAPI Backend
* ğŸ¨ Clean & Modern HTML/CSS Frontend
* ğŸš« No Chain-of-Thought / Thinking Tokens Shown

---

## ğŸ§© Tech Stack

### Backend

* FastAPI
* LangChain
* FAISS
* HuggingFace Embeddings (`all-MiniLM-L6-v2`)
* ChatCerebras (Qwen-3-32B)
* YouTube Transcript API
* Pydantic
* Python

### Frontend

* HTML
* CSS
* JavaScript (Fetch Streaming API)

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ Backend/
â”‚   â”œâ”€â”€ rag_with_chain.py      # RAG pipeline + streaming logic
â”‚   â”œâ”€â”€ routes.py              # FastAPI routes
â”‚   â”œâ”€â”€ schema.py              # Pydantic input schema
â”‚   â”œâ”€â”€ transcript.py          # YouTube transcript extraction
â”‚
â”œâ”€â”€ index.html                 # Frontend UI
â”œâ”€â”€ .env                       # Environment variables
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ” How It Works (Flow)

1. User enters:

   * YouTube video URL
   * Question
2. Backend:

   * Extracts video transcript
   * Splits transcript into chunks
   * Generates embeddings
   * Stores embeddings in FAISS
   * Retrieves top relevant chunks
3. LLM:

   * Uses **ONLY retrieved context**
   * Streams response token-by-token
4. Frontend:

   * Displays live streamed answer
   * Removes `<think>` / reasoning output

---

## ğŸ§  RAG Prompt Design

The system prompt enforces:

* Answer **ONLY from transcript**
* No chain-of-thought
* Structured & clear answers
* Graceful fallback if info not found

```
Use ONLY the provided transcript context.
Do NOT include your reasoning, chain-of-thought, or internal thinking.
Provide ONLY the final answer in a clear, structured format.
```

---

## ğŸ“¡ API Endpoint

### POST `/chat-stream`

**Request Body**

```json
{
  "url": "https://www.youtube.com/watch?v=VIDEO_ID",
  "prompt": "Your question here"
}
```

**Response**

* `text/plain`
* Streamed response (chunk-by-chunk)

---

## ğŸ–¥ï¸ Frontend Preview

* Gradient modern UI
* Live typing indicator
* Markdown-style formatting
* Auto-scroll streaming output
* Error handling for backend issues

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone Repository

```bash
git clone <your-repo-url>
cd <project-folder>
```

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Environment Variables (`.env`)

```env
CEREBRAS_API_KEY=your_api_key_here
```

---

## â–¶ï¸ Run Backend Server

```bash
uvicorn Backend.routes:app --reload
```

Backend runs at:

```
http://127.0.0.1:8000
```

---

## ğŸŒ Run Frontend

Simply open:

```
index.html
```

in your browser.

---

## âš ï¸ Limitations

* Only works for videos with English transcripts
* Transcript-based answers only (no hallucination)
* Requires valid Cerebras API key

---

## ğŸš§ Future Improvements

* Multi-language transcript support
* Persistent vector storage
* Authentication
* Mobile-friendly UI
* Multi-video RAG support

---

## ğŸ™Œ Credits

* LangChain
* Cerebras
* HuggingFace
* YouTube Transcript API
* FastAPI

---

## ğŸ“œ Project Author 
Pratik naik
Walchand College of engineering sangli

